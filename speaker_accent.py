# -*- coding: utf-8 -*-
"""speaker accent.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1ym5HB_p05QCn9X7SlNGZGaBJiT-PLCkQ
"""

import numpy as np
import pandas as pd
import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Dropout
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import accuracy_score

# Load the dataset
data = pd.read_csv('/content/accent-mfcc-data-1.csv')  # Corrected path to the uploaded file

# Load the dataset
url = "/content/accent-mfcc-data-1.csv"
data = pd.read_csv(url)

# Display the first few rows to understand the structure
print(data.head())

# Check column names and data types
print(data.columns)
print(data.info())

import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from tensorflow.keras.utils import to_categorical

# Load the dataset
# Load the dataset
data = pd.read_csv('/content/accent-mfcc-data-1.csv')


# Display the first few rows and column names to understand the structure
print(data.head())
print(data.columns)
# Check column names to identify the correct target column
print(data.columns)

# Define features (X) and target variable (y)
X = data.drop(columns=['language'])  # Replace 'Accent' with the correct column name
y = data['language']  # Replace with the correct target column name




# Convert categorical labels into numeric values if needed (one-hot encoding)
y = pd.factorize(y)[0]

# Split the dataset into training and test sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Standardize the features
scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)

# Optionally, one-hot encode the target for multi-class classification
y_train = to_categorical(y_train)
y_test = to_categorical(y_test)

from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Dropout

# Define the model
model = Sequential([
    Dense(128, input_dim=X_train.shape[1], activation='relu'), # connected to every neuron in the previous layer
    Dropout(0.3),
    Dense(64, activation='relu'),
    Dropout(0.3),
    Dense(32, activation='relu'),
    Dropout(0.3),
    Dense(y_train.shape[1], activation='softmax')  # Softmax for multi-class classification
])

# Compile the model
model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])

# Train the model. epoch(training process will go through the entire training dataset 50 times.)
history = model.fit(X_train, y_train, epochs=50, batch_size=32, validation_split=0.2)

# Evaluate model accuracy on the test data
test_loss, test_accuracy = model.evaluate(X_test, y_test)
print(f'Test accuracy: {test_accuracy:.2%}')

# Convert the model to TensorFlow Lite format (to convert big data into compress small data)
converter = tf.lite.TFLiteConverter.from_keras_model(model)
tflite_model = converter.convert()

# Save the model as .tfile
with open('speaker_accent_model.tfile', 'wb') as f:
    f.write(tflite_model)

# Convert the TFLite model to a hex format(data that would be stored in RAM )
hex_model = tflite_model.hex()

# Save the model as a C header file (to declare functions)
with open('speaker_accent_model.h', 'w') as f:
    f.write('#ifndef SPEAKER_ACCENT_MODEL_H\n')
    f.write('#define SPEAKER_ACCENT_MODEL_H\n\n')
    f.write('const unsigned char speaker_accent_model[] = {\n')
    for i in range(0, len(hex_model), 2):
        f.write(f'0x{hex_model[i:i+2]}, ')
        if (i + 2) % 20 == 0:
            f.write('\n')
    f.write('};\n\n')
    f.write('#endif')

# Save the model as an H5 file
model.save('speaker_accent_model.h5')



from tensorflow.keras.models import load_model

# Load the model from the H5 file
loaded_model = load_model('speaker_accent_model.h5')

# Check the model summary
loaded_model.summary()